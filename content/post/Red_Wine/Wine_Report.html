---
date: 2018-04-09T10:58:08-04:00
description: "Random Forest"
featured_image: "/images/wine.jpg"
tags: ["data analysis", "random forest", "correlation plot", "exploratory analysis"]
title: "Red Wine Analysis"
---



<p>Objective: My objective was to see if I could predict whether a wine was good or bad using the Random Forest Algorithm (using Random Forest and FFTrees). To run the model I train it on 70% of the data. I then test it against the test set or the other 30% to see how it does. Before I start the random Forest I do some Exploratory Analysis to see those factors that contribute to a wine being classified a Good Wine.</p>
<p>Conlusion: The Random Forest model outperformed the FFTrees model. Alcohol, Acidity, and Sulphates were the biggest contributors to whether the wine was ranked greater than 6. Overall, a fun project and good practice.</p>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<pre><code>## corrplot 0.84 loaded</code></pre>
<pre><code>## randomForest 4.6-14</code></pre>
<pre><code>## Type rfNews() to see new features/changes/bug fixes.</code></pre>
<pre><code>## 
## Attaching package: &#39;randomForest&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:ggplot2&#39;:
## 
##     margin</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     combine</code></pre>
<pre><code>##    O</code></pre>
<pre><code>##   / \</code></pre>
<pre><code>##  F   O</code></pre>
<pre><code>##     / \</code></pre>
<pre><code>##    F   T</code></pre>
<pre><code>## FFTrees v1.3.5. Email: Nathaniel.D.Phillips.is@gmail.com</code></pre>
<pre><code>## FFTrees.guide() opens the package guide. Citation info at citation(&#39;FFTrees&#39;)</code></pre>
<pre><code>##  fixed.acidity   volatile.acidity  citric.acid    residual.sugar  
##  Min.   : 4.60   Min.   :0.1200   Min.   :0.000   Min.   : 0.900  
##  1st Qu.: 7.10   1st Qu.:0.3900   1st Qu.:0.090   1st Qu.: 1.900  
##  Median : 7.90   Median :0.5200   Median :0.260   Median : 2.200  
##  Mean   : 8.32   Mean   :0.5278   Mean   :0.271   Mean   : 2.539  
##  3rd Qu.: 9.20   3rd Qu.:0.6400   3rd Qu.:0.420   3rd Qu.: 2.600  
##  Max.   :15.90   Max.   :1.5800   Max.   :1.000   Max.   :15.500  
##    chlorides       free.sulfur.dioxide total.sulfur.dioxide
##  Min.   :0.01200   Min.   : 1.00       Min.   :  6.00      
##  1st Qu.:0.07000   1st Qu.: 7.00       1st Qu.: 22.00      
##  Median :0.07900   Median :14.00       Median : 38.00      
##  Mean   :0.08747   Mean   :15.87       Mean   : 46.47      
##  3rd Qu.:0.09000   3rd Qu.:21.00       3rd Qu.: 62.00      
##  Max.   :0.61100   Max.   :72.00       Max.   :289.00      
##     density             pH          sulphates         alcohol     
##  Min.   :0.9901   Min.   :2.740   Min.   :0.3300   Min.   : 8.40  
##  1st Qu.:0.9956   1st Qu.:3.210   1st Qu.:0.5500   1st Qu.: 9.50  
##  Median :0.9968   Median :3.310   Median :0.6200   Median :10.20  
##  Mean   :0.9967   Mean   :3.311   Mean   :0.6581   Mean   :10.42  
##  3rd Qu.:0.9978   3rd Qu.:3.400   3rd Qu.:0.7300   3rd Qu.:11.10  
##  Max.   :1.0037   Max.   :4.010   Max.   :2.0000   Max.   :14.90  
##     quality     
##  Min.   :3.000  
##  1st Qu.:5.000  
##  Median :6.000  
##  Mean   :5.636  
##  3rd Qu.:6.000  
##  Max.   :8.000</code></pre>
<pre><code>## &#39;data.frame&#39;:    1599 obs. of  12 variables:
##  $ fixed.acidity       : num  7.4 7.8 7.8 11.2 7.4 7.4 7.9 7.3 7.8 7.5 ...
##  $ volatile.acidity    : num  0.7 0.88 0.76 0.28 0.7 0.66 0.6 0.65 0.58 0.5 ...
##  $ citric.acid         : num  0 0 0.04 0.56 0 0 0.06 0 0.02 0.36 ...
##  $ residual.sugar      : num  1.9 2.6 2.3 1.9 1.9 1.8 1.6 1.2 2 6.1 ...
##  $ chlorides           : num  0.076 0.098 0.092 0.075 0.076 0.075 0.069 0.065 0.073 0.071 ...
##  $ free.sulfur.dioxide : num  11 25 15 17 11 13 15 15 9 17 ...
##  $ total.sulfur.dioxide: num  34 67 54 60 34 40 59 21 18 102 ...
##  $ density             : num  0.998 0.997 0.997 0.998 0.998 ...
##  $ pH                  : num  3.51 3.2 3.26 3.16 3.51 3.51 3.3 3.39 3.36 3.35 ...
##  $ sulphates           : num  0.56 0.68 0.65 0.58 0.56 0.56 0.46 0.47 0.57 0.8 ...
##  $ alcohol             : num  9.4 9.8 9.8 9.8 9.4 9.4 9.4 10 9.5 10.5 ...
##  $ quality             : int  5 5 5 6 5 5 5 7 7 5 ...</code></pre>
<p>I can clearly see that there are fewer wines ranked over 6.</p>
<p><img src="/post/Red_Wine/Wine_Report_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>For practice I am going to set a binary variable. A 1 for a wine greater than <strong>6</strong> and <strong>0</strong> if else. In essence we’re going to predict 1’s and 0’s.</p>
<pre class="r"><code>df$goodwine &lt;- ifelse(df$quality &gt; 6, 1, 0)</code></pre>
<pre class="r"><code>table(df$goodwine)</code></pre>
<pre><code>## 
##    0    1 
## 1382  217</code></pre>
<p>We can see that there are 217 good wines and 1,382 not good. We are going to attempt to identify good wines from a data set the model has not seen. But first back to EA.</p>
<pre class="r"><code>ggplot(df,aes(x=goodwine,fill=factor(goodwine)))+geom_bar(stat = &quot;count&quot;,position = &quot;dodge&quot;)+
  scale_x_continuous(breaks = seq(0,1,1))+
  ggtitle(&quot;Distribution of Good and Bad Wines&quot;) +
  theme_bw()</code></pre>
<p><img src="/post/Red_Wine/Wine_Report_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>I use the pairs function to get a quick idea of the correlations or lack thereof in the data.</p>
<pre class="r"><code>pairs(df)</code></pre>
<p><img src="/post/Red_Wine/Wine_Report_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>This is a different way to show the correlations of above. Perhaps easier to read. This shows that the highest correlated varaibles to <em>quality</em> in the data set are alchol content and sulphates. Let’s plot those out next to each other.</p>
<pre class="r"><code>corrplot(cor(df))</code></pre>
<p><img src="/post/Red_Wine/Wine_Report_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>We can see that the Good Wines have lower Acidity Levels than those under a rating of 6.</p>
<pre class="r"><code>ggplot(df,aes(x=volatile.acidity,fill=factor(goodwine)))+geom_density(alpha=0.25)+
  geom_vline(aes(xintercept=mean(volatile.acidity[goodwine==0],na.rm=T)),color=&quot;red&quot;,linetype=&quot;dashed&quot;,lwd=1)+
  geom_vline(aes(xintercept=mean(volatile.acidity[goodwine==1],na.rm=T)),color=&quot;blue&quot;,linetype=&quot;dashed&quot;,lwd=1)+
  scale_x_continuous(breaks = seq(0,1.6,0.1))+
  xlab(label = &quot;Volatile Acidity Level&quot;)+
  ggtitle(&quot;Distribution of Volatile Acidity Levels&quot;)+
  theme_bw()</code></pre>
<p><img src="/post/Red_Wine/Wine_Report_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>The Good Wines have a higher Sulphate Level as seen in the Distribution below.</p>
<pre class="r"><code>ggplot(df,aes(x=sulphates,fill=factor(goodwine)))+geom_density(alpha=0.25)+
  geom_vline(aes(xintercept=mean(sulphates[goodwine==0],na.rm=T)),color=&quot;red&quot;,linetype=&quot;dashed&quot;,lwd=1)+
  geom_vline(aes(xintercept=mean(sulphates[goodwine==1],na.rm=T)),color=&quot;blue&quot;,linetype=&quot;dashed&quot;,lwd=1)+
  scale_x_continuous(breaks = seq(0,1.6,0.1))+
  xlab(label = &quot;Volatile Sulphate Level&quot;)+
  ggtitle(&quot;Distribution of Volatile Sulphate Levels&quot;)+
  theme_bw()</code></pre>
<p><img src="/post/Red_Wine/Wine_Report_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>Acidity levels are higher in Good Wines.</p>
<pre class="r"><code>ggplot(df,aes(x=citric.acid,fill=factor(goodwine)))+geom_density(alpha=0.25)+
  geom_vline(aes(xintercept=mean(citric.acid[goodwine==0],na.rm=T)),color=&quot;red&quot;,linetype=&quot;dashed&quot;,lwd=1)+
  geom_vline(aes(xintercept=mean(citric.acid[goodwine==1],na.rm=T)),color=&quot;blue&quot;,linetype=&quot;dashed&quot;,lwd=1)+
  scale_x_continuous(breaks = seq(0,1.6,0.1))+
  xlab(label = &quot;Volatile Acidity Level&quot;)+
  ggtitle(&quot;Distribution of Volatile Acidity Levels&quot;)+
  theme_bw()</code></pre>
<p><img src="/post/Red_Wine/Wine_Report_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>Alchol was the highest correlated variable to the quality ranking at a correlation of .8 out of 1. This can also be visualized below.</p>
<pre class="r"><code>ggplot(df,aes(x=alcohol,fill=factor(goodwine)))+geom_density(alpha=0.25)+
  geom_vline(aes(xintercept=mean(alcohol[goodwine==0],na.rm=T)),color=&quot;red&quot;,linetype=&quot;dashed&quot;,lwd=1)+
  geom_vline(aes(xintercept=mean(alcohol[goodwine==1],na.rm=T)),color=&quot;blue&quot;,linetype=&quot;dashed&quot;,lwd=1)+
  scale_x_continuous(breaks = seq(1,15,2))+
  xlab(label = &quot;Volatile Alchohol Level&quot;)+
  ggtitle(&quot;Distribution of Volatile Alcohol Levels&quot;)+
  theme_bw()</code></pre>
<p><img src="/post/Red_Wine/Wine_Report_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>Ok that was interesting. But I want to see if I can use the data to build a predictive model. First I’m going to split the data frame into a training and test set.</p>
<pre class="r"><code>rows &lt;- sample(1:nrow(df), nrow(df) * .7)
train &lt;- df[rows,]
test &lt;- df[-rows,]</code></pre>
<p>Now I am going to run the Random Forest Algorithm and store the model in rf.</p>
<pre class="r"><code>rf &lt;- randomForest(factor(goodwine) ~ .-quality, train, ntrees = 300)</code></pre>
<p>It’s time to predict. I’m going to test the model on data the model has not seen to avoid overfitting.</p>
<p>Based on the test the model shows an accuracy of 90%. There were 33 missclassified bad wines and 16 good wines. Overall the model has a high sensitivity.<br />
In another run I would balance the data since there are few Good Wines as a percentage of Bad wines.</p>
<pre class="r"><code>library(caret)</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<pre class="r"><code>predict1 &lt;- predict(rf, test)

confusionMatrix(predict1, as.factor(test$goodwine))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 412  31
##          1  15  22
##                                          
##                Accuracy : 0.9042         
##                  95% CI : (0.8742, 0.929)
##     No Information Rate : 0.8896         
##     P-Value [Acc &gt; NIR] : 0.17232        
##                                          
##                   Kappa : 0.4379         
##  Mcnemar&#39;s Test P-Value : 0.02699        
##                                          
##             Sensitivity : 0.9649         
##             Specificity : 0.4151         
##          Pos Pred Value : 0.9300         
##          Neg Pred Value : 0.5946         
##              Prevalence : 0.8896         
##          Detection Rate : 0.8583         
##    Detection Prevalence : 0.9229         
##       Balanced Accuracy : 0.6900         
##                                          
##        &#39;Positive&#39; Class : 0              
## </code></pre>
<p>A good question is what variables have the biggest impact on what is considered a good wine?</p>
<p>As we seen with the corrplot above the answer is nearly the same. Alcohol is the single biggest factor, acidity followed by sulphates.</p>
<pre class="r"><code>importance    &lt;- importance(rf)

varImportance &lt;- data.frame(Variables = row.names(importance), 
                            Importance = round(importance[ ,&#39;MeanDecreaseGini&#39;],2))

# Create a rank variable based on importance
rankImportance &lt;- varImportance %&gt;%
  mutate(Rank = paste0(&#39;#&#39;,dense_rank(desc(Importance))))

# Use ggplot2 to visualize the relative importance of variables
ggplot(rankImportance, aes(x = reorder(Variables, Importance), 
                           y = Importance, fill = Importance)) +
  geom_bar(stat=&#39;identity&#39;) + 
  geom_text(aes(x = Variables, y = 0.5, label = Rank),
            hjust=0, vjust=0.55, size = 4, colour = &#39;red&#39;) +
  labs(x = &#39;Variables&#39;) +
  coord_flip() + 
  theme_few()</code></pre>
<p><img src="/post/Red_Wine/Wine_Report_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>Fast and Furious Trees is another algorithm. I want to compare it to the tried and true Random Forest.</p>
<pre class="r"><code>rf2 &lt;- FFTrees(goodwine ~ ., train, test)</code></pre>
<pre><code>## Growing FFTs with ifan</code></pre>
<pre><code>## Fitting non-FFTrees algorithms for comparison (you can turn this off with do.comp = FALSE) ...</code></pre>
<p>The Fast and Furious Model didn’t perform as well as it had misclassified 60 Good Wines. This graph is great because it quickly gives some metrics by which we could use right away. For example, if alchol content is less than 10.4 then it won’t be considered a Good Wine, ect.</p>
<pre class="r"><code>plot(rf2)</code></pre>
<p><img src="/post/Red_Wine/Wine_Report_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>This graph is great. If you needed one variable to predict you could use alcohol content greater than 6. That would classify most of your wines. Pretty handy if you’re tasting a bunch of wines looking for the one that would be considered Good.</p>
<pre class="r"><code>plot(rf2, what = &quot;cues&quot;)</code></pre>
<p><img src="/post/Red_Wine/Wine_Report_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
