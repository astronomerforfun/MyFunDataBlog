---
date: 2018-04-09T10:58:08-04:00
description: "Random Forest"
featured_image: "/images/wine.jpg"
tags: ["data analysis", "random forest", "correlation plot", "exploratory analysis"]
title: "Red Wine Analysis"
---



<p>Objective: My objective was to see if I could predict whether a wine was good or bad using the Random Forest Algorithm (using Random Forest and FFTrees). To run the model I train it on 70% of the data. I then test it against the test set or the other 30% to see how it does. Before I start the random Forest I do some Exploratory Analysis to see those factors that contribute to a wine being classified a Good Wine.</p>
<p>Conlusion: The Random Forest model outperformed the FFTrees model. Alcohol, Acidity, and Sulphates were the biggest contributors to whether the wine was ranked greater than 6. Overall, a fun project and good practice.</p>
<p>I can clearly see that there are fewer wines ranked over 6.</p>
<p><img src="/post/Red_Wine/Wine_Report_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>For practice I am going to set a binary variable. A 1 for a wine ranked greater than <strong>6</strong> and <strong>0</strong> if 6 or under.</p>
<pre class="r"><code>df$goodwine &lt;- ifelse(df$quality &gt; 6, 1, 0)</code></pre>
<p>We can see that there are 217 wines with rankings over 6 and 1,382 with a ranking 6 or less. Back to Exploratory Analysis.</p>
<pre class="r"><code>table(df$goodwine)</code></pre>
<pre><code>## 
##    0    1 
## 1382  217</code></pre>
<p>A visual representation of the table above.</p>
<pre class="r"><code>ggplot(df,aes(x=goodwine,fill=factor(goodwine)))+geom_bar(stat = &quot;count&quot;,position = &quot;dodge&quot;)+
  scale_x_continuous(breaks = seq(0,1,1))+
  ggtitle(&quot;Distribution of Good and Bad Wines&quot;) +
  theme_bw()</code></pre>
<p><img src="/post/Red_Wine/Wine_Report_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>I use the pairs function to get a quick idea of the correlations or lack thereof in the data.</p>
<pre class="r"><code>pairs(df)</code></pre>
<p><img src="/post/Red_Wine/Wine_Report_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>This is a different way to show the correlations of above. Perhaps easier to read. This shows that the highest correlated varaibles to <em>quality</em> in the data set are alchol content and sulphates. Let’s plot those out next to each other.</p>
<pre class="r"><code>corrplot(cor(df))</code></pre>
<p><img src="/post/Red_Wine/Wine_Report_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>We can see that the Good Wines have lower Acidity Levels than those under a rating of 6.</p>
<pre class="r"><code>ggplot(df,aes(x=volatile.acidity,fill=factor(goodwine)))+geom_density(alpha=0.25)+
  geom_vline(aes(xintercept=mean(volatile.acidity[goodwine==0],na.rm=T)),color=&quot;red&quot;,linetype=&quot;dashed&quot;,lwd=1)+
  geom_vline(aes(xintercept=mean(volatile.acidity[goodwine==1],na.rm=T)),color=&quot;blue&quot;,linetype=&quot;dashed&quot;,lwd=1)+
  scale_x_continuous(breaks = seq(0,1.6,0.1))+
  xlab(label = &quot;Volatile Acidity Level&quot;)+
  ggtitle(&quot;Distribution of Volatile Acidity Levels&quot;)+
  theme_bw()</code></pre>
<p><img src="/post/Red_Wine/Wine_Report_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>The Good Wines have a higher Sulphate Level as seen in the Distribution below.</p>
<pre class="r"><code>ggplot(df,aes(x=sulphates,fill=factor(goodwine)))+geom_density(alpha=0.25)+
  geom_vline(aes(xintercept=mean(sulphates[goodwine==0],na.rm=T)),color=&quot;red&quot;,linetype=&quot;dashed&quot;,lwd=1)+
  geom_vline(aes(xintercept=mean(sulphates[goodwine==1],na.rm=T)),color=&quot;blue&quot;,linetype=&quot;dashed&quot;,lwd=1)+
  scale_x_continuous(breaks = seq(0,1.6,0.1))+
  xlab(label = &quot;Volatile Sulphate Level&quot;)+
  ggtitle(&quot;Distribution of Volatile Sulphate Levels&quot;)+
  theme_bw()</code></pre>
<p><img src="/post/Red_Wine/Wine_Report_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>Acidity levels are higher in Good Wines.</p>
<pre class="r"><code>ggplot(df,aes(x=citric.acid,fill=factor(goodwine)))+geom_density(alpha=0.25)+
  geom_vline(aes(xintercept=mean(citric.acid[goodwine==0],na.rm=T)),color=&quot;red&quot;,linetype=&quot;dashed&quot;,lwd=1)+
  geom_vline(aes(xintercept=mean(citric.acid[goodwine==1],na.rm=T)),color=&quot;blue&quot;,linetype=&quot;dashed&quot;,lwd=1)+
  scale_x_continuous(breaks = seq(0,1.6,0.1))+
  xlab(label = &quot;Volatile Acidity Level&quot;)+
  ggtitle(&quot;Distribution of Volatile Acidity Levels&quot;)+
  theme_bw()</code></pre>
<p><img src="/post/Red_Wine/Wine_Report_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>Alchol was the highest correlated variable to the quality ranking at a correlation of .8 out of 1. This can also be visualized below.</p>
<pre class="r"><code>ggplot(df,aes(x=alcohol,fill=factor(goodwine)))+geom_density(alpha=0.25)+
  geom_vline(aes(xintercept=mean(alcohol[goodwine==0],na.rm=T)),color=&quot;red&quot;,linetype=&quot;dashed&quot;,lwd=1)+
  geom_vline(aes(xintercept=mean(alcohol[goodwine==1],na.rm=T)),color=&quot;blue&quot;,linetype=&quot;dashed&quot;,lwd=1)+
  scale_x_continuous(breaks = seq(1,15,2))+
  xlab(label = &quot;Volatile Alchohol Level&quot;)+
  ggtitle(&quot;Distribution of Volatile Alcohol Levels&quot;)+
  theme_bw()</code></pre>
<p><img src="/post/Red_Wine/Wine_Report_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>Ok that was interesting. But it’s model time. First I’m going to split the data frame into a training and test set and take out the Quality Variable.</p>
<pre class="r"><code>df &lt;- df[,-12]
rows &lt;- sample(1:nrow(df), nrow(df) * .7)
train &lt;- df[rows,]
test &lt;- df[-rows,]</code></pre>
<p>Now I am going to run the Random Forest Algorithm and store the model in rf.</p>
<pre class="r"><code>rf &lt;- randomForest(factor(goodwine) ~ ., train, ntrees = 300)</code></pre>
<p>It’s time to predict. I’m going to test the model on data the model has not seen to avoid overfitting.</p>
<p>Based on the test the model shows an accuracy of 92%. There were 22 missclassified bad wines and 16 good wines. Overall the model has a high sensitivity.<br />
In another run I would balance the data since there are few Good Wines as a percentage of Bad wines.</p>
<pre class="r"><code>library(caret)</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<pre class="r"><code>set.seed(1234)
predict1 &lt;- predict(rf, test)

confusionMatrix(predict1, as.factor(test$goodwine))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 395  38
##          1  13  34
##                                           
##                Accuracy : 0.8938          
##                  95% CI : (0.8627, 0.9199)
##     No Information Rate : 0.85            
##     P-Value [Acc &gt; NIR] : 0.0032406       
##                                           
##                   Kappa : 0.5138          
##  Mcnemar&#39;s Test P-Value : 0.0007775       
##                                           
##             Sensitivity : 0.9681          
##             Specificity : 0.4722          
##          Pos Pred Value : 0.9122          
##          Neg Pred Value : 0.7234          
##              Prevalence : 0.8500          
##          Detection Rate : 0.8229          
##    Detection Prevalence : 0.9021          
##       Balanced Accuracy : 0.7202          
##                                           
##        &#39;Positive&#39; Class : 0               
## </code></pre>
<p>A good question is what variables have the biggest impact on what is considered a good wine?</p>
<p>As we seen with the corrplot above the answer is nearly the same. Alcohol is the single biggest factor, sulphates followed by acidity.</p>
<pre class="r"><code>importance    &lt;- importance(rf)

varImportance &lt;- data.frame(Variables = row.names(importance), 
                            Importance = round(importance[ ,&#39;MeanDecreaseGini&#39;],2))

# Create a rank variable based on importance
rankImportance &lt;- varImportance %&gt;%
  mutate(Rank = paste0(&#39;#&#39;,dense_rank(desc(Importance))))

# Use ggplot2 to visualize the relative importance of variables
ggplot(rankImportance, aes(x = reorder(Variables, Importance), 
                           y = Importance, fill = Importance)) +
  geom_bar(stat=&#39;identity&#39;) + 
  geom_text(aes(x = Variables, y = 0.5, label = Rank),
            hjust=0, vjust=0.55, size = 4, colour = &#39;red&#39;) +
  labs(x = &#39;Variables&#39;) +
  coord_flip() + 
  theme_few()</code></pre>
<p><img src="/post/Red_Wine/Wine_Report_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>Fast and Furious Trees is another algorithm. I want to compare it to the tried and true Random Forest.</p>
<pre class="r"><code>rf2 &lt;- FFTrees(goodwine ~ ., train, test)</code></pre>
<pre><code>## Growing FFTs with ifan</code></pre>
<pre><code>## Fitting non-FFTrees algorithms for comparison (you can turn this off with do.comp = FALSE) ...</code></pre>
<p>The Fast and Furious Model didn’t perform as well as it had misclassified 60 Good Wines as Bad wines. This graph, however, is great because it quickly gives some metrics by which we could use right away.</p>
<p>If you needed one variable to predict you could use alcohol content greater than 10.75. That would classify most of your wines properly (about 80% of the time with that one metric alone).</p>
<pre class="r"><code>plot(rf2, what = &quot;cues&quot;)</code></pre>
<p><img src="/post/Red_Wine/Wine_Report_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>I hope you enjoyed this analysis.</p>
