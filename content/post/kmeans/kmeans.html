---
date: 2018-10-28T10:58:08-04:00
description: "K-Means Clustering  (Beginner) by Chris Shockley"
featured_image: "/images/petal.jpg"
tags: ["unsupervised learning", "k means", "machine learning" ]
title: "Can the k means algorithm correctly identify a flower by its petal length and width?"
---



<div id="k-means-clustering" class="section level2">
<h2>K Means Clustering</h2>
<p>K Means Clustering is awesome. It’s what’s called unsupervised learning. The algorithm attemps to cluster data based on its similarity. So in my case I’m going to feed it the petal width and petal length of three sets of flowers and see if it can appropriately group the data. This of course is much different than trying to predict some variable.</p>
<p>To implement k means we have to specify the number of clusters we want the data to be grouped into. The algorithm then will randomly assign each observation to a cluster, and finds the centroid (center) of each cluster. Then the algorithm iterates through two steps:</p>
<ol style="list-style-type: decimal">
<li>Reassign data points to cluster whose centroid is closest.</li>
<li>Calculate new centroid of each cluster.</li>
</ol>
<p>These two steps are repeated till the within cluster variation cannot be reduced any further. The within cluster variation is calculated as the sum of the euclidean distance (remember high school?) between the data points and their respective cluster centroids. Don’t worry the computer does all this for me and you. Otherwise I would likely not be into machine learning. <br></p>
<div id="objective" class="section level4">
<h4><strong>Objective:</strong></h4>
<p>To use the k means to estimate which Species of flower the different petal lenghts belong to. <br></p>
</div>
<div id="conlcusion" class="section level4">
<h4><strong>Conlcusion:</strong></h4>
<p>The k means cluster analsis is simple to use. It is also accurate. I was able to feed the widths and lengths and it accurately grouped the data. When compared to the actual data for testing the algorithm had a 96% accuracy.<br />
<br></p>
</div>
<div id="lets-get-started" class="section level4">
<h4><strong>Let’s Get Started:</strong></h4>
<p>The Iris Dataset consists of 150 observations with 5 variables. For the k means we will only use petal.length and petal.width. But before we run the k means let’s look at how its clustered with the names intact. Remember. Later we will strip out the names and let k means find the Name. Pretty cool.</p>
<p><br></p>
<p>This is a graphical representation of the data the three different species are plotted.</p>
<p>Next we will strip out the Species and see if it the k means can find the proper group just looking at the data.</p>
<pre class="r"><code>library(ggplot2)
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point()</code></pre>
<p><img src="/post/kmeans/kmeans_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>Now we know in this example there are three groups (we have the answer) But if we didn’t know we’d apply some different methods to find the appropriate group number. Save that for a different post. For now though let’s just use 3 groups.</p>
<pre class="r"><code>set.seed(20) #for reproducibility
irisCluster &lt;- kmeans(iris[, 3:4], 3, nstart = 20) #
irisCluster</code></pre>
<pre><code>## K-means clustering with 3 clusters of sizes 50, 52, 48
## 
## Cluster means:
##   Petal.Length Petal.Width
## 1     1.462000    0.246000
## 2     4.269231    1.342308
## 3     5.595833    2.037500
## 
## Clustering vector:
##   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
##  [36] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
##  [71] 2 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3
## [106] 3 2 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 2 3
## [141] 3 3 3 3 3 3 3 3 3 3
## 
## Within cluster sum of squares by cluster:
## [1]  2.02200 13.05769 16.29167
##  (between_SS / total_SS =  94.3 %)
## 
## Available components:
## 
## [1] &quot;cluster&quot;      &quot;centers&quot;      &quot;totss&quot;        &quot;withinss&quot;    
## [5] &quot;tot.withinss&quot; &quot;betweenss&quot;    &quot;size&quot;         &quot;iter&quot;        
## [9] &quot;ifault&quot;</code></pre>
<p><br></p>
<p>Ok. Let’s see how we did graphically. It looks like there are nice three tightly knit clusters.</p>
<p>Let’s see <strong>exactly</strong> how we did by comparing the algorithm to the actual data.</p>
<pre class="r"><code>irisCluster$cluster &lt;- as.factor(irisCluster$cluster)
ggplot(iris, aes(Petal.Length, Petal.Width, color = irisCluster$cluster)) + geom_point()</code></pre>
<p><img src="/post/kmeans/kmeans_files/figure-html/unnamed-chunk-4-1.png" width="672" /> <br></p>
<p>We can see that it properly classified all the Satosa’s. It miss classified 2 of the Versicolors. And it misclassified 4 of the Virginicas. The accuracy would then be <em>Total Correctly Grouped</em>/<em>Totally Correctly Grouped + Total Incorrectly Grouped</em> or 96%. Not bad.</p>
<pre class="r"><code>table(irisCluster$cluster, iris$Species)</code></pre>
<pre><code>##    
##     setosa versicolor virginica
##   1     50          0         0
##   2      0         48         4
##   3      0          2        46</code></pre>
<p>Well that’s it. A beginners look at k means. I’m looking forward to posting some tougher ones in the future.</p>
<p>I hope you enjoyed.</p>
</div>
</div>
