<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Caret on Chris&#39;s Data Blog</title>
    <link>/tags/caret/</link>
    <description>Recent content in Caret on Chris&#39;s Data Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 10 Nov 2018 10:58:08 -0400</lastBuildDate>
    
	<atom:link href="/tags/caret/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Google -- Thank you for giving us Tensorflow and Keras...</title>
      <link>/post/keras_ctg/script/</link>
      <pubDate>Sat, 10 Nov 2018 10:58:08 -0400</pubDate>
      
      <guid>/post/keras_ctg/script/</guid>
      <description>First what is Deep Learning?Deep Learning. What? Ok I confess. I know how to implement some of these deep(er) learning algorithms, but I’m just now getting my brain around what they are. And as caveat. I’m focused driven. My thinking is if I test my model on new data (data the model hasn’t seen) many times over and get good results, what the heck do I care how the thing works under the hood?</description>
    </item>
    
    <item>
      <title>Complete Review of the Random Forest Package</title>
      <link>/post/randomforest/rfscript/</link>
      <pubDate>Mon, 05 Nov 2018 10:58:08 -0400</pubDate>
      
      <guid>/post/randomforest/rfscript/</guid>
      <description>Random Forest Package ReviewObjective:I wanted to learn about the Random Forest package. See what its strengths and weaknesses are. By doing this case study (inspired by Bharatendra Rai) I really have a much better understanding of the package. Moreover by writing it out and I am reinforcing my learning and helping out newcomers to the world of R and machine learning. I hope you enjoy.
Read in DataCTG Data:</description>
    </item>
    
    <item>
      <title>What?  Hypertune Using glmnet and Caret by Max Kuhn?  Pass it along.</title>
      <link>/post/glmnet/glmnet/</link>
      <pubDate>Mon, 05 Nov 2018 10:58:08 -0400</pubDate>
      
      <guid>/post/glmnet/glmnet/</guid>
      <description>Objective:So in this blog I am going to go through a lesson I recently took with a gentlemen by the name Bharatendra Rai, where he goes through the glmnet model in detail.
The reason this model is great is that you can hypretune it, which you will see momentarily. It is an equal to the Random Forests but where glmnet takes the lead is with the amount of information you can pull from the model and its parameters.</description>
    </item>
    
  </channel>
</rss>