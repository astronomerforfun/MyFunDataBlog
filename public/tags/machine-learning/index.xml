<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Chris&#39;s Data Blog</title>
    <link>/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on Chris&#39;s Data Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 Nov 2018 10:58:08 -0400</lastBuildDate>
    
	<atom:link href="/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>The ROC Curve - Is it a Mine or a Rock? - Pick your Sensitivity</title>
      <link>/post/roc/roc/</link>
      <pubDate>Tue, 06 Nov 2018 10:58:08 -0400</pubDate>
      
      <guid>/post/roc/roc/</guid>
      <description>The Famous ROC CurveROC stands for Receiver Operating Characteristic. Its origin is from sonar back in the 40’s, where it was used to identify submarines. The ROC curve was an important metric in WWII and continues to be today.
Today the ROC curve is used in predictive modelling to distinguish between true positives and true negatives. But if you’re like me you need to see it in action to really understand.</description>
    </item>
    
    <item>
      <title>Complete Review of the Random Forest Package</title>
      <link>/post/randomforest/rfscript/</link>
      <pubDate>Mon, 05 Nov 2018 10:58:08 -0400</pubDate>
      
      <guid>/post/randomforest/rfscript/</guid>
      <description>Random Forest Package ReviewObjective:I wanted to learn about the Random Forest package. See what its strengths and weaknesses are. By doing this case study (inspired by Bharatendra Rai) I really have a throrough understanding of the package. Moreover by writing it out and I am reinforcing my learning and helping out newcomers to the world of R and machine learning. I hope you enjoy.
Read in DataCTG Data:</description>
    </item>
    
    <item>
      <title>What?  Hypertune Using glmnet and Caret by Max Kuhn?  Pass it along.</title>
      <link>/post/glmnet/glmnet/</link>
      <pubDate>Mon, 05 Nov 2018 10:58:08 -0400</pubDate>
      
      <guid>/post/glmnet/glmnet/</guid>
      <description>Objective:So in this blog I am going to go through a lesson I recently took with a gentlemen by the name Bharatendra Rai, where he goes through the glmnet model in detail.
The reason this model is great is that you can hypretune it, which you will see momentarily. It is an equal to the Random Forests but where glmnet takes the lead is with the amount of information you can pull from the model and its parameters.</description>
    </item>
    
    <item>
      <title>Can the k means algorithm correctly identify a flower by its petal length and width alone?</title>
      <link>/post/kmeans/kmeans/</link>
      <pubDate>Sun, 28 Oct 2018 10:58:08 -0400</pubDate>
      
      <guid>/post/kmeans/kmeans/</guid>
      <description>K Means ClusteringK Means Clustering is awesome. It’s what’s called unsupervised learning where there is no prediction variable. The algorithm attemps to cluster data based on its similarity. So in this case I’m going to feed the algorithm the petal width and petal length of three sets of flowers and see whether or not can appropriately group the data.
To implement k means we have to specify the number of clusters we want the data to be grouped into.</description>
    </item>
    
  </channel>
</rss>