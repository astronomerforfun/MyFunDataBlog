<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Models on Chris&#39;s Data Blog</title>
    <link>/tags/models/</link>
    <description>Recent content in Models on Chris&#39;s Data Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 10 Nov 2018 10:58:08 -0400</lastBuildDate>
    
	<atom:link href="/tags/models/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Google -- Thank you for giving us Tensorflow and Keras...</title>
      <link>/post/keras_ctg/script/</link>
      <pubDate>Sat, 10 Nov 2018 10:58:08 -0400</pubDate>
      
      <guid>/post/keras_ctg/script/</guid>
      <description>First what is Deep Learning?Deep Learning. What? Ok I confess. I know how to implement some of these deep(er) learning algorithms, but I’m just now getting my brain around what they are. And as caveat. I’m focused driven. My thinking is if I test my model on new data (data the model hasn’t seen) many times over and get good results, what the heck do I care how the thing works under the hood?</description>
    </item>
    
    <item>
      <title>Complete Review of the Random Forest Package</title>
      <link>/post/randomforest/rfscript/</link>
      <pubDate>Mon, 05 Nov 2018 10:58:08 -0400</pubDate>
      
      <guid>/post/randomforest/rfscript/</guid>
      <description>Random Forest Package ReviewObjective:I wanted to learn about the Random Forest package. See what its strengths and weaknesses are. By doing this case study (inspired by Bharatendra Rai) I really have a much better understanding of the package. Moreover by writing it out and I am reinforcing my learning and helping out newcomers to the world of R and machine learning. I hope you enjoy.
Read in DataCTG Data:</description>
    </item>
    
    <item>
      <title>What?  Hypertune Using glmnet and Caret by Max Kuhn?  Pass it along.</title>
      <link>/post/glmnet/glmnet/</link>
      <pubDate>Mon, 05 Nov 2018 10:58:08 -0400</pubDate>
      
      <guid>/post/glmnet/glmnet/</guid>
      <description>Objective:So in this blog I am going to go through a lesson I recently took with a gentlemen by the name Bharatendra Rai, where he goes through the glmnet model in detail.
The reason this model is great is that you can hypretune it, which you will see momentarily. It is an equal to the Random Forests but where glmnet takes the lead is with the amount of information you can pull from the model and its parameters.</description>
    </item>
    
    <item>
      <title>How many sunny days are followed by cloudy days in Seattle on any given year?</title>
      <link>/post/weather_post/mkdown/</link>
      <pubDate>Sun, 28 Oct 2018 10:58:08 -0400</pubDate>
      
      <guid>/post/weather_post/mkdown/</guid>
      <description>Seattle Sunny Day StreaksObjective: If you’re like me when the sun comes out after a couple cloudy days my mood lifts quite a bit - even more so than when it’s been sunny for a couple days. Perhaps its the contrast between the two? Nevertheless I was curious how many shifts on average we will have from cloudy days to sunny days, in other words how many mood lifts can we estimate to have in a year living in Seattle.</description>
    </item>
    
  </channel>
</rss>